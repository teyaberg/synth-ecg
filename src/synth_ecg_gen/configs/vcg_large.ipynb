{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-convention",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import perturb_ecg\n",
    "import tools\n",
    "import tqdm\n",
    "import vcg\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits import mplot3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a2564f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mp.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0d22aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "\n",
    "\n",
    "SMALL_SIZE = 15\n",
    "MEDIUM_SIZE = 20\n",
    "BIGGER_SIZE = 25\n",
    "\n",
    "plt.rc(\"font\", size=SMALL_SIZE)  # controls default text sizes\n",
    "plt.rc(\"axes\", titlesize=SMALL_SIZE)  # fontsize of the axes title\n",
    "plt.rc(\"axes\", labelsize=MEDIUM_SIZE)  # fontsize of the x and y labels\n",
    "plt.rc(\"xtick\", labelsize=SMALL_SIZE)  # fontsize of the tick labels\n",
    "plt.rc(\"ytick\", labelsize=SMALL_SIZE)  # fontsize of the tick labels\n",
    "plt.rc(\"legend\", fontsize=SMALL_SIZE)  # legend fontsize\n",
    "plt.rc(\"figure\", titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee2bac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030535d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"ecg_large\"\n",
    "if not os.path.exists(dataset):\n",
    "    os.makedirs(f\"./{dataset}/train\")\n",
    "    os.makedirs(f\"./{dataset}/val/train\")\n",
    "    os.makedirs(f\"./{dataset}/val/test\")\n",
    "\n",
    "fs = 496  # frequency\n",
    "duration = 100  # seconds to solve\n",
    "save_duration = 10  # seconds to save\n",
    "dur = save_duration * fs  # number of samples to save\n",
    "upper_hr = 220\n",
    "lower_hr = 20\n",
    "hr_step = 0.1\n",
    "draw_num = 2\n",
    "types = 8\n",
    "\n",
    "\n",
    "keys = pd.DataFrame(\n",
    "    np.random.randint(\n",
    "        0, (duration - save_duration) * fs, size=(int((upper_hr - lower_hr) / hr_step), draw_num * types)\n",
    "    )\n",
    ")\n",
    "keys.columns = [\n",
    "    \"ind0\",\n",
    "    \"ind1\",\n",
    "    \"ind2\",\n",
    "    \"ind3\",\n",
    "    \"ind4\",\n",
    "    \"ind5\",\n",
    "    \"ind6\",\n",
    "    \"ind7\",\n",
    "    \"ind8\",\n",
    "    \"ind9\",\n",
    "    \"ind10\",\n",
    "    \"ind11\",\n",
    "    \"ind12\",\n",
    "    \"ind13\",\n",
    "    \"ind14\",\n",
    "    \"ind15\",\n",
    "]\n",
    "\n",
    "keys[\"hr\"] = range(lower_hr * 10, upper_hr * 10)\n",
    "keysc = keys.sample(frac=0.2)\n",
    "keysc[\"train\"] = int(0)\n",
    "val_keys = keysc.sample(frac=0.2)\n",
    "val_keys[\"val_train\"] = int(0)\n",
    "key = keysc.merge(val_keys, how=\"outer\")\n",
    "df_key = keys.merge(key, how=\"outer\")\n",
    "df_key = df_key.fillna(1)\n",
    "df_key[\"val_train\"].value_counts()\n",
    "df_key[\"train\"] = df_key[\"train\"].astype(int)\n",
    "df_key[\"val_train\"] = df_key[\"val_train\"].astype(int)\n",
    "df_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625ac720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def amp_qrs(vcg_ode_original, scale=1.5):\n",
    "\n",
    "    vcg_ode = copy.deepcopy(vcg_ode_original)\n",
    "\n",
    "    b_x = vcg_ode.b_x\n",
    "    b_y = vcg_ode.b_y\n",
    "    b_z = vcg_ode.b_z\n",
    "\n",
    "    alpha_x = vcg_ode.alpha_x\n",
    "    alpha_y = vcg_ode.alpha_y\n",
    "    alpha_z = vcg_ode.alpha_z\n",
    "\n",
    "    # make bigger\n",
    "    alpha_x[3] *= scale\n",
    "    alpha_x[4] *= scale\n",
    "    alpha_x[5] *= scale\n",
    "\n",
    "    alpha_y[3] *= scale\n",
    "    alpha_y[4] *= scale\n",
    "    alpha_y[5] *= scale\n",
    "\n",
    "    alpha_z[3] *= scale\n",
    "    alpha_z[4] *= scale\n",
    "    alpha_z[5] *= scale\n",
    "\n",
    "    vcg_ode.b_x = b_x\n",
    "    vcg_ode.b_y = b_y\n",
    "    vcg_ode.b_z = b_z\n",
    "\n",
    "    vcg_ode.alpha_x = alpha_x\n",
    "    vcg_ode.alpha_y = alpha_y\n",
    "    vcg_ode.alpha_z = alpha_z\n",
    "\n",
    "    return vcg_ode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5624f57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def amp_pwave1(vcg_ode_original, scale=25):\n",
    "\n",
    "    vcg_ode = copy.deepcopy(vcg_ode_original)\n",
    "\n",
    "    b_x = vcg_ode.b_x\n",
    "    b_y = vcg_ode.b_y\n",
    "    b_z = vcg_ode.b_z\n",
    "\n",
    "    alpha_x = vcg_ode.alpha_x\n",
    "    alpha_y = vcg_ode.alpha_y\n",
    "    alpha_z = vcg_ode.alpha_z\n",
    "\n",
    "    # make bigger\n",
    "    alpha_x[0] *= scale\n",
    "    #     alpha_x[1] *= scale\n",
    "\n",
    "    #     alpha_y[0] *= scale\n",
    "    #     alpha_y[1] *= scale\n",
    "    #     alpha_y[2] *= scale\n",
    "\n",
    "    #     alpha_z[0] *= scale\n",
    "    #     alpha_z[1] *= scale\n",
    "    #     alpha_z[2] *= scale\n",
    "\n",
    "    vcg_ode.b_x = b_x\n",
    "    vcg_ode.b_y = b_y\n",
    "    vcg_ode.b_z = b_z\n",
    "\n",
    "    vcg_ode.alpha_x = alpha_x\n",
    "    vcg_ode.alpha_y = alpha_y\n",
    "    vcg_ode.alpha_z = alpha_z\n",
    "\n",
    "    return vcg_ode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deefec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def amp_pwave2(vcg_ode_original, scale=25):\n",
    "\n",
    "    vcg_ode = copy.deepcopy(vcg_ode_original)\n",
    "\n",
    "    b_x = vcg_ode.b_x\n",
    "    b_y = vcg_ode.b_y\n",
    "    b_z = vcg_ode.b_z\n",
    "\n",
    "    alpha_x = vcg_ode.alpha_x\n",
    "    alpha_y = vcg_ode.alpha_y\n",
    "    alpha_z = vcg_ode.alpha_z\n",
    "\n",
    "    # make bigger\n",
    "    alpha_x[0] *= scale\n",
    "    #     alpha_x[1] *= scale\n",
    "\n",
    "    alpha_y[0] *= scale\n",
    "    #     alpha_y[1] *= scale\n",
    "    #     alpha_y[2] *= scale\n",
    "\n",
    "    alpha_z[0] *= scale\n",
    "    #     alpha_z[1] *= scale\n",
    "    #     alpha_z[2] *= scale\n",
    "\n",
    "    vcg_ode.b_x = b_x\n",
    "    vcg_ode.b_y = b_y\n",
    "    vcg_ode.b_z = b_z\n",
    "\n",
    "    vcg_ode.alpha_x = alpha_x\n",
    "    vcg_ode.alpha_y = alpha_y\n",
    "    vcg_ode.alpha_z = alpha_z\n",
    "\n",
    "    return vcg_ode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c14393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def amp_twave(vcg_ode_original, scale=5):\n",
    "\n",
    "    vcg_ode = copy.deepcopy(vcg_ode_original)\n",
    "\n",
    "    b_x = vcg_ode.b_x\n",
    "    b_y = vcg_ode.b_y\n",
    "    b_z = vcg_ode.b_z\n",
    "\n",
    "    alpha_x = vcg_ode.alpha_x\n",
    "    alpha_y = vcg_ode.alpha_y\n",
    "    alpha_z = vcg_ode.alpha_z\n",
    "\n",
    "    # make bigger\n",
    "    alpha_x[8] *= scale\n",
    "    #     alpha_x[4] *= scale\n",
    "    #     alpha_x[5] *= scale\n",
    "\n",
    "    #     alpha_y[8] *= scale\n",
    "    #     alpha_y[4] *= scale\n",
    "    #     alpha_y[5] *= scale\n",
    "\n",
    "    #     alpha_z[8] *= scale\n",
    "    #     alpha_z[4] *= scale\n",
    "    #     alpha_z[5] *= scale\n",
    "\n",
    "    vcg_ode.b_x = b_x\n",
    "    vcg_ode.b_y = b_y\n",
    "    vcg_ode.b_z = b_z\n",
    "\n",
    "    vcg_ode.alpha_x = alpha_x\n",
    "    vcg_ode.alpha_y = alpha_y\n",
    "    vcg_ode.alpha_z = alpha_z\n",
    "\n",
    "    return vcg_ode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1885f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def st_change(vcg_ode_original, scale=6):\n",
    "\n",
    "    vcg_ode = copy.deepcopy(vcg_ode_original)\n",
    "\n",
    "    b_x = vcg_ode.b_x\n",
    "    b_y = vcg_ode.b_y\n",
    "    b_z = vcg_ode.b_z\n",
    "\n",
    "    alpha_x = vcg_ode.alpha_x\n",
    "    alpha_y = vcg_ode.alpha_y\n",
    "    alpha_z = vcg_ode.alpha_z\n",
    "\n",
    "    # make bigger\n",
    "    #     alpha_x[6] *= scale\n",
    "    #     alpha_x[4] *= scaled\n",
    "    #     alpha_x[6] *= scale\n",
    "    alpha_x[6] *= scale\n",
    "\n",
    "    alpha_y[6] *= scale\n",
    "    #     alpha_y[7] *= scale\n",
    "    #     alpha_y[5] *= scale\n",
    "\n",
    "    #     alpha_z[8] *= scale\n",
    "    #     alpha_z[4] *= scale\n",
    "    #     alpha_z[6] *= scale\n",
    "\n",
    "    vcg_ode.b_x = b_x\n",
    "    vcg_ode.b_y = b_y\n",
    "    vcg_ode.b_z = b_z\n",
    "\n",
    "    vcg_ode.alpha_x = alpha_x\n",
    "    vcg_ode.alpha_y = alpha_y\n",
    "    vcg_ode.alpha_z = alpha_z\n",
    "\n",
    "    return vcg_ode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22b7d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ecgs(row):\n",
    "\n",
    "    # find folder for the ecgs to go in\n",
    "    if row[17] == 1:\n",
    "        path = f\"./{dataset}/train\"\n",
    "    elif row[18] == 1:\n",
    "        path = f\"./{dataset}/val/train\"\n",
    "    else:\n",
    "        path = f\"./{dataset}/val/test/\"\n",
    "\n",
    "    for i in range(0, 8):\n",
    "        if not os.path.isdir(f\"{path}/{row[16]}_{i}\"):\n",
    "            os.mkdirs(f\"{path}/{row[16]}_{i}\")\n",
    "    # make the base ode solves\n",
    "    vcg_ode = vcg.VCG(row[16] / 10)\n",
    "    # get actual arrays of values and save\n",
    "    # orig\n",
    "    _, y0 = tools.solve_vcg_object(vcg_ode, duration=duration, fs=fs)\n",
    "    pd.DataFrame(y0[row[0] : row[0] + save_duration * fs, :].T).to_csv(\n",
    "        f\"{path}/{row[16]}_0/{row[16]}_0_{row[0]}.csv\", header=False, index=False\n",
    "    )\n",
    "    pd.DataFrame(y0[row[1] : row[1] + save_duration * fs, :].T).to_csv(\n",
    "        f\"{path}/{row[16]}_0/{row[16]}_0_{row[1]}.csv\", header=False, index=False\n",
    "    )\n",
    "    # qt_elong\n",
    "    vcg_ode2 = perturb_ecg.qt_elongation(vcg_ode, ms_forward=np.random.randint(50, 250))\n",
    "    _, y1 = tools.solve_vcg_object(vcg_ode2, duration=duration, fs=fs)\n",
    "    pd.DataFrame(y1[row[2] : row[2] + save_duration * fs, :].T).to_csv(\n",
    "        f\"{path}/{row[16]}_1/{row[16]}_1_{row[2]}.csv\", header=False, index=False\n",
    "    )\n",
    "    pd.DataFrame(y1[row[3] : row[3] + save_duration * fs, :].T).to_csv(\n",
    "        f\"{path}/{row[16]}_1/{row[16]}_1_{row[3]}.csv\", header=False, index=False\n",
    "    )\n",
    "    # wide_qrs\n",
    "    vcg_ode3 = perturb_ecg.wide_qrs(\n",
    "        vcg_ode, percent_widened=np.random.randint(200, 1000), scaledown=(np.random.randint(10, 100) / 100)\n",
    "    )\n",
    "    _, y2 = tools.solve_vcg_object(vcg_ode3, duration=duration, fs=fs)\n",
    "    pd.DataFrame(y2[row[4] : row[4] + save_duration * fs, :].T).to_csv(\n",
    "        f\"{path}/{row[16]}_2/{row[16]}_2_{row[4]}.csv\", header=False, index=False\n",
    "    )\n",
    "    pd.DataFrame(y2[row[5] : row[5] + save_duration * fs, :].T).to_csv(\n",
    "        f\"{path}/{row[16]}_2/{row[16]}_2_{row[5]}.csv\", header=False, index=False\n",
    "    )\n",
    "    # amp_qrs\n",
    "    vcg_ode4 = amp_qrs(vcg_ode, scale=(np.random.randint(8, 30) / 10))\n",
    "    _, y3 = tools.solve_vcg_object(vcg_ode4, duration=duration, fs=fs)\n",
    "    pd.DataFrame(y3[row[6] : row[6] + save_duration * fs, :].T).to_csv(\n",
    "        f\"{path}/{row[16]}_3/{row[16]}_3_{row[6]}.csv\", header=False, index=False\n",
    "    )\n",
    "    pd.DataFrame(y3[row[7] : row[7] + save_duration * fs, :].T).to_csv(\n",
    "        f\"{path}/{row[16]}_3/{row[16]}_3_{row[7]}.csv\", header=False, index=False\n",
    "    )\n",
    "    # amp_pwave1\n",
    "    vcg_ode5 = amp_pwave1(vcg_ode, scale=np.random.randint(2, 50))\n",
    "    _, y4 = tools.solve_vcg_object(vcg_ode5, duration=duration, fs=fs)\n",
    "    pd.DataFrame(y4[row[8] : row[8] + save_duration * fs, :].T).to_csv(\n",
    "        f\"{path}/{row[16]}_4/{row[16]}_4_{row[8]}.csv\", header=False, index=False\n",
    "    )\n",
    "    pd.DataFrame(y4[row[9] : row[9] + save_duration * fs, :].T).to_csv(\n",
    "        f\"{path}/{row[16]}_4/{row[16]}_4_{row[9]}.csv\", header=False, index=False\n",
    "    )\n",
    "    # amp_pwave2\n",
    "    vcg_ode6 = amp_pwave2(vcg_ode, scale=np.random.randint(2, 50))\n",
    "    _, y5 = tools.solve_vcg_object(vcg_ode6, duration=duration, fs=fs)\n",
    "    pd.DataFrame(y5[row[10] : row[10] + save_duration * fs, :].T).to_csv(\n",
    "        f\"{path}/{row[16]}_5/{row[16]}_5_{row[10]}.csv\", header=False, index=False\n",
    "    )\n",
    "    pd.DataFrame(y5[row[11] : row[11] + save_duration * fs, :].T).to_csv(\n",
    "        f\"{path}/{row[16]}_5/{row[16]}_5_{row[11]}.csv\", header=False, index=False\n",
    "    )\n",
    "    # amp_twave\n",
    "    vcg_ode7 = amp_twave(vcg_ode, scale=np.random.randint(2, 10))\n",
    "    _, y6 = tools.solve_vcg_object(vcg_ode7, duration=duration, fs=fs)\n",
    "    pd.DataFrame(y6[row[12] : row[12] + save_duration * fs, :].T).to_csv(\n",
    "        f\"{path}/{row[16]}_6/{row[16]}_6_{row[12]}.csv\", header=False, index=False\n",
    "    )\n",
    "    pd.DataFrame(y6[row[13] : row[13] + save_duration * fs, :].T).to_csv(\n",
    "        f\"{path}/{row[16]}_6/{row[16]}_6_{row[13]}.csv\", header=False, index=False\n",
    "    )\n",
    "    # st_change\n",
    "    vcg_ode8 = st_change(vcg_ode, scale=np.random.randint(2, 10))\n",
    "    _, y7 = tools.solve_vcg_object(vcg_ode8, duration=duration, fs=fs)\n",
    "    pd.DataFrame(y7[row[14] : row[14] + save_duration * fs, :].T).to_csv(\n",
    "        f\"{path}/{row[16]}_7/{row[16]}_7_{row[14]}.csv\", header=False, index=False\n",
    "    )\n",
    "    pd.DataFrame(y7[row[15] : row[15] + save_duration * fs, :].T).to_csv(\n",
    "        f\"{path}/{row[16]}_7/{row[16]}_7_{row[15]}.csv\", header=False, index=False\n",
    "    )\n",
    "\n",
    "    del vcg_ode\n",
    "    del vcg_ode2\n",
    "    del vcg_ode3\n",
    "    del vcg_ode4\n",
    "    del vcg_ode5\n",
    "    del vcg_ode6\n",
    "    del vcg_ode7\n",
    "    del vcg_ode8\n",
    "\n",
    "    print(row[16])\n",
    "    return [row[16], path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c77316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert keys to list for pool\n",
    "key_list = df_key.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f300d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = mp.Pool(mp.cpu_count())\n",
    "results = pool.map(make_ecgs, [row for row in key_list])\n",
    "print(\"Done!\")\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a762420c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_key.to_csv(f\"./{dataset}/ecg_keys.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec72280",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
